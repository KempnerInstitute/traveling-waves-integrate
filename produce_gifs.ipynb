{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch\n",
    "from utils import make_model, set_random_seed, save_model, load_model\n",
    "from trainer import train\n",
    "from dataset import ShapeDataset, load_data\n",
    "from dataset_config import DATASET_CONFIG\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import fastcluster\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting import plot_phases, plot_results, plot_eval, plot_fourier, plot_phases2, plot_masks, plot_slots, build_color_mask, plot_clusters, plot_clusters2\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a YAML file\n",
    "def load_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)['params']\n",
    "\n",
    "folders = [\n",
    "    \"ccn8/new_tetronimoes/conv_recurrent2/5/linear_lstm_20iters\",\n",
    "    \"ccn8/new_tetronimoes/cornn_model2/9/linear_100iters\",\n",
    "    \"ccn17/multi_mnist/cornn_model2/11/linear_smaller4_0-100iters_16hc\",\n",
    "]\n",
    "folder = 'experiments'\n",
    "hydra_config_file = '.hydra/config.yaml'\n",
    "paths = [f\"{folder}/{curr}\" for curr in folders]\n",
    "\n",
    "configs = [load_yaml_file(f\"{p}/{hydra_config_file}\") for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "seed = 1\n",
    "set_random_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(cp_folder, config, device, data_config):\n",
    "    net = make_model(\n",
    "        device,\n",
    "        config['model_type'],\n",
    "        config['num_classes'],\n",
    "        config['N'],\n",
    "        config['dt'],\n",
    "        config['min_iters'],\n",
    "        config['max_iters'],\n",
    "        data_config['channels'],\n",
    "        config['c_mid'],\n",
    "        config['hidden_channels'],\n",
    "        config['rnn_kernel'],\n",
    "        data_config['img_size'],\n",
    "        config['kernel_init'],\n",
    "        cell_type=config['cell_type'],\n",
    "        num_layers=config['num_layers'],\n",
    "        readout_type=config['readout_type'],\n",
    "    )\n",
    "    net.load_state_dict(torch.load(f\"{cp_folder}/cp.pt\", \n",
    "                                   map_location=torch.device('cpu')), \n",
    "                                   strict=False)\n",
    "    net.eval()\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [load_model(paths[i], configs[i], device, DATASET_CONFIG[configs[i]['dataset']]) for i in range(len(paths))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_readout(net, y_seq, B, H, W):\n",
    "    y_seq = y_seq.reshape(B, net.T, net.c_out, -1)\n",
    "    y_seq = y_seq.transpose(1, 3)\n",
    "    fft_vals = net.fc_time(y_seq)\n",
    "    fft_mag = fft_vals.transpose(1, 3) # (B, K, C, H*W)\n",
    "    fft_mag = fft_mag.reshape(B, fft_mag.size(1), fft_mag.size(2), H, W)\n",
    "    return fft_mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_config1 = DATASET_CONFIG['new_tetronimoes']\n",
    "data_config2 = DATASET_CONFIG['multi_mnist']\n",
    "_, valset1, _ = load_data('new_tetronimoes', data_config1)\n",
    "_, valset2, _ = load_data('multi_mnist', data_config2)\n",
    "\n",
    "val_loader = DataLoader(valset1, batch_size=16, shuffle=True, drop_last=False)\n",
    "batch1 = next(iter(val_loader))\n",
    "val_loader = DataLoader(valset2, batch_size=16, shuffle=True, drop_last=False)\n",
    "batch2 = next(iter(val_loader))\n",
    "\n",
    "testsets = {\n",
    "    'new_tetronimoes' : batch1,\n",
    "    'multi_mnist' : batch2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "ffts = []\n",
    "masks = []\n",
    "for i, net in enumerate(models):\n",
    "    config = configs[i]\n",
    "    dataset = config['dataset']\n",
    "    batch = testsets[dataset]\n",
    "    x, x_target = batch\n",
    "    batch_size = x.size(0)\n",
    "    x = x.to(device) #torch.Size([16, 2, 3, 40, 40]) \n",
    "    logits, y_seq = net(x)\n",
    "    fft_mag = linear_readout(net.classifier, y_seq, x.size(0), x.size(-2), x.size(-1))\n",
    "    states.append(y_seq)\n",
    "    ffts.append(fft_mag)\n",
    "    masks.append(logits.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states[0].shape, states[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ffts[0].shape, ffts[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(masks[0].shape, masks[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_masks(masks, title):\n",
    "    masks = masks.detach().cpu().numpy()\n",
    "    fig, axes = plt.subplots(1, 16, figsize=(16, 1))\n",
    "    for i in range(16):\n",
    "        axes[i].imshow(masks[i])\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "    axes[0].set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, net in enumerate(models):\n",
    "    plot_masks(masks[i], title=configs[i]['model_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2, 4, 5, 7, 8, 9, 10, 11, 12\n",
    "samples = [1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at gifs and choose timesteps we want to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hidden_state_video(y_seq, sample_idx=0, interval=200, fpath=None):\n",
    "    \"\"\"\n",
    "    Given y_seq of shape (T,B,H,W), animate the hidden state for the sample\n",
    "    `sample_idx` across timesteps T.\n",
    "    \n",
    "    - `interval` controls the animation speed (milliseconds between frames).\n",
    "    - returns: HTML object that, when displayed in Jupyter, shows the animation.\n",
    "    \"\"\"\n",
    "    T, B, H, W = y_seq.shape\n",
    "    assert 0 <= sample_idx < B, f\"sample_idx must be in [0..{B-1}]\"\n",
    "    \n",
    "    # Subsample to 100 frames if sequence is too long\n",
    "    if T > 100:\n",
    "        indices = np.linspace(0, T-1, 100, dtype=int)\n",
    "        y_seq = y_seq[indices]\n",
    "        T = 100\n",
    "    \n",
    "    # We'll animate frames across t=0..T-1\n",
    "    #  shape => (T,H,W)\n",
    "    y_seq_np = y_seq[:, sample_idx].cpu().numpy()  # -> (T,H,W)\n",
    "    \n",
    "    # We can pick vmin/vmax across the entire timeseries for a stable color scale\n",
    "    vmin = y_seq_np.min()\n",
    "    vmax = y_seq_np.max()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(y_seq_np[0], cmap='bwr', vmin=vmin, vmax=vmax)\n",
    "    #ax.set_title(f\"Hidden state evolution (sample={sample_idx})\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    #fig.tight_layout()\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    def animate(t):\n",
    "        im.set_array(y_seq_np[t])\n",
    "        ax.set_xlabel(f\"t = {t}\")\n",
    "        return [im]\n",
    "    \n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, animate, \n",
    "        frames=T, \n",
    "        interval=interval, \n",
    "        blit=True\n",
    "    )\n",
    "\n",
    "    if fpath is not None:\n",
    "        ani.save(f'{fpath}.gif', writer='pillow', fps=5)\n",
    "\n",
    "    plt.close(fig)  # so that we don't get a duplicate static plot\n",
    "    #return HTML(ani.to_jshtml())\n",
    "\n",
    "def plot_hidden(y, sample, channel, interval=200, fpath=None):\n",
    "    y = torch.transpose(y, 0, 1).detach()\n",
    "    return plot_hidden_state_video(y[:,:,channel], sample_idx=sample, interval=200, fpath=fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_folder = \"gifs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    fpath = f\"{gif_folder}/tetronimoes_lstm_sample-{sample}\"\n",
    "    plot_hidden(states[0], sample=sample, channel=1, fpath=fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    fpath = f\"{gif_folder}/tetronimoes_cornn_sample-{sample}\"\n",
    "    plot_hidden(states[1], sample=sample, channel=1, fpath=fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    fpath = f\"{gif_folder}/multi_mnist_cornn_sample-{sample}\"\n",
    "    plot_hidden(states[2], sample=sample, channel=1, fpath=fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
